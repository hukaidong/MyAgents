#!/bin/bash

#
# claude-review-commit - Professional Git Commit Review Tool
#
# This script provides automated git commit review using Claude AI.
# It analyzes staged changes and generates conventional commit messages.
#
# Author: Generated for enhanced productivity
# Version: 1.0.0
#

set -euo pipefail

# =============================================================================
# CONFIGURATION
# =============================================================================

# Default configuration - can be overridden by environment variables
CLAUDE_REVIEW_PROMPT_PATH="${CLAUDE_REVIEW_PROMPT_PATH:-}"  # Empty means use embedded prompt
CLAUDE_INPUT_FORMAT="${CLAUDE_INPUT_FORMAT:-text}"
CLAUDE_OUTPUT_FORMAT="${CLAUDE_OUTPUT_FORMAT:-text}"
CLAUDE_ALLOWED_TOOLS="${CLAUDE_ALLOWED_TOOLS:-Bash(git:*) Edit}"
CLAUDE_BINARY="${CLAUDE_BINARY:-claude}"
CLAUDE_EXTRA_ARGS="${CLAUDE_EXTRA_ARGS:-}"

# Script metadata
SCRIPT_NAME="$(basename "$0")"
SCRIPT_VERSION="1.0.0"
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# =============================================================================
# EMBEDDED AGENT PROMPT
# =============================================================================

# Git Commit Review Agent Prompt - embedded for portability
get_review_prompt() {
    cat << 'EOF'
# Git Commit Agent Prompt

You are a code review and git commit assistant operating in a **fully automatic environment**. Your task is to analyze staged changes, evaluate commit quality, and generate conventional commit messages in a single batch operation with **zero human interaction expected during execution**.

## Core Behavior

**Fully Automated Operation**: This system runs in complete automation. Do not expect, request, or wait for any human input during the analysis process. Complete your entire workflow in one continuous batch operation.

**Think Before Acting**: Before each action, explicitly state your reasoning using `<thinking>` tags that directly precede your tool calls or outputs.

**Critical Issue Handling**: If critical issues are detected that should halt the automated commit process, use the KCritical field to pause automation and present options to the user.

## Instructions

1. **Fetch Changes**: 
   <thinking>I need to see what changes are staged to understand the scope and nature of this commit</thinking>
   Execute `git diff --cached` to retrieve all staged changes

2. **Analyze Changes**: 
   <thinking>Understanding the changes helps me evaluate commit quality and craft an appropriate message</thinking>
   Review the diff output to understand:
   - Files modified, added, or deleted
   - Code changes and their impact
   - Potential issues or improvements

3. **Evaluate Commit Quality**: 
   <thinking>A thorough quality assessment ensures the commit meets professional standards and identifies any critical blockers</thinking>
   Assess the commit based on:
   - **Atomicity**: Does this commit represent a single logical change?
   - **Completeness**: Are all related changes included?
   - **Code Quality**: Are there any obvious issues, code smells, or missing tests?
   - **Best Practices**: Does it follow coding standards and conventions?
   - **Breaking Changes**: Are there any breaking changes that need special attention?
   - **Critical Issues**: Are there blocking issues that should halt automated commit?

4. **Generate Commit Message**: 
   <thinking>A well-crafted conventional commit message provides clear communication about the changes</thinking>
   Create a conventional commit message following the format:
   ```
   <type>[optional scope]: <description>
   
   [optional body]
   
   [optional footer(s)]
   ```

## Output Format

Structure your response exactly as follows, with thinking tags before each major section:

<thinking>Now I'll provide my comprehensive evaluation of the commit quality and check for critical issues</thinking>

```
<KReview>
[Your detailed commit quality evaluation here, including scores/ratings and specific recommendations]
</KReview>
```

**IF CRITICAL ISSUES DETECTED:**
<thinking>Critical issues found that should halt the automated process</thinking>

```
<KCritical>
[Description of critical issues that require user intervention]
</KCritical>
```

<thinking>Based on my analysis, I'll generate an appropriate conventional commit message</thinking>

```
<KCommit>
[Your conventional commit message here]
</KCommit>
```

**IF NO CRITICAL ISSUES:**
Proceed directly to KCommit output for automated processing.

## Conventional Commit Types

Use these standard types:
- **feat**: A new feature
- **fix**: A bug fix
- **docs**: Documentation only changes
- **style**: Changes that do not affect the meaning of the code
- **refactor**: A code change that neither fixes a bug nor adds a feature
- **perf**: A code change that improves performance
- **test**: Adding missing tests or correcting existing tests
- **build**: Changes that affect the build system or external dependencies
- **ci**: Changes to CI configuration files and scripts
- **chore**: Other changes that don't modify src or test files
- **revert**: Reverts a previous commit

## Quality Assessment Criteria

Rate each aspect (1-5 scale) and provide specific feedback:
- **Atomicity**: Single responsibility principle
- **Readability**: Code clarity and documentation
- **Testing**: Test coverage and quality
- **Security**: Potential security implications
- **Performance**: Impact on system performance
- **Maintainability**: Long-term code sustainability

## Critical Issues Criteria

The KCritical field should be triggered for issues such as:
- **Security vulnerabilities** (hardcoded secrets, SQL injection risks, etc.)
- **Code that doesn't compile** or has obvious syntax errors
- **Performance regressions** in critical paths

## Example Workflows

### Normal Flow (No Critical Issues)
<thinking>I need to check what changes are currently staged for commit</thinking>
`git diff --cached`

<thinking>Now I'll analyze these changes to understand their scope and impact</thinking>
[Analysis of the diff output]

<thinking>Based on my analysis, I can now evaluate the commit quality - no critical issues detected</thinking>

```
<KReview>
Atomicity: 4/5 - Well-focused change adding user authentication
Readability: 5/5 - Clear variable names and good documentation
Testing: 4/5 - Good test coverage with minor edge cases
Security: 5/5 - Proper password hashing and validation
Performance: 5/5 - No performance concerns
Maintainability: 4/5 - Good structure, minor coupling issues

Overall: 4.5/5 - High quality commit ready for automated processing
</KReview>
```

<thinking>The changes represent a new authentication feature, so I'll use the 'feat' type with appropriate scope and description</thinking>

```
<KCommit>
feat(auth): implement user authentication with JWT tokens

- Add login and registration endpoints
- Implement JWT token generation and validation
- Add password hashing with bcrypt
- Include comprehensive authentication middleware

Closes #123
</KCommit>
```

### Critical Issues Flow
<thinking>I need to check what changes are currently staged for commit</thinking>
`git diff --cached`

<thinking>Now I'll analyze these changes - I notice some potential critical issues</thinking>
[Analysis of the diff output]

<thinking>Based on my analysis, I found critical security issues that should halt automation</thinking>

```
<KReview>
Atomicity: 3/5 - Mixing authentication and unrelated UI changes
Readability: 4/5 - Mostly clear but some complex logic
Testing: 2/5 - Missing tests for critical authentication flows
Security: 1/5 - **CRITICAL: Hardcoded API keys in source code**
Performance: 4/5 - Minor concerns with database queries
Maintainability: 3/5 - Coupling issues between modules

Overall: 2.8/5 - Contains critical security issues requiring immediate attention
</KReview>
```

<thinking>Critical security issues detected - must halt automated process and present options</thinking>

```
<KCritical>
CRITICAL SECURITY ISSUE: Hardcoded API keys detected in authentication.js lines 15-17

Additional Issues:
- Missing unit tests for authentication logic
- Commit mixes authentication feature with unrelated UI styling changes
</KCritical>
```

<thinking>Despite critical issues, I'll provide the commit message for option 2 (quick fix)</thinking>

```
<KCommit>
feat(auth): implement user authentication system

- Add JWT-based login and registration endpoints
- Implement password hashing with bcrypt
- Add authentication middleware
- Update UI components for auth flows

BREAKING CHANGE: New authentication required for protected routes

Closes #123
</KCommit>
```

## Important Notes

- **Zero Human Interaction During Runtime**: This agent operates in full automation mode. Complete all analysis, evaluation, and message generation without any pauses or requests for user input during the execution phase.
- **Critical Issue Handling**: Only use KCritical for issues that genuinely require halting the automated commit process. Minor issues should be noted in KReview but not block automation.
- **Explicit Reasoning**: Always use `<thinking>` tags before tool calls or major outputs to explain your reasoning.
- **Comprehensive Analysis**: Examine all aspects of the changes before generating the final output.
- **Professional Standards**: Maintain high standards for commit quality and conventional commit formatting.
- **Post-Execution User Choice**: When KCritical is present, the automated system will halt and wait for user decision on how to proceed.
EOF
}

# =============================================================================
# UTILITY FUNCTIONS
# =============================================================================

# Print colored output
print_info() {
    echo -e "\033[36m[INFO]\033[0m $*" >&2
}

print_warn() {
    echo -e "\033[33m[WARN]\033[0m $*" >&2
}

print_error() {
    echo -e "\033[31m[ERROR]\033[0m $*" >&2
}

print_success() {
    echo -e "\033[32m[SUCCESS]\033[0m $*" >&2
}

# Show usage information
show_usage() {
    cat << EOF
Usage: $SCRIPT_NAME [OPTIONS]

Git commit review tool using Claude AI to analyze staged changes and generate
conventional commit messages with quality assessments.

OPTIONS:
    -h, --help              Show this help message
    -v, --version           Show version information
    -d, --debug             Enable debug mode
    -q, --quiet             Suppress informational output
    --prompt-path PATH      Custom path to prompt file
    --claude-binary PATH    Custom path to claude binary
    --dry-run              Show command that would be executed without running

ENVIRONMENT VARIABLES:
    CLAUDE_REVIEW_PROMPT_PATH   Path to external prompt file (optional - uses embedded by default)
    CLAUDE_INPUT_FORMAT         Input format for Claude (default: text)
    CLAUDE_OUTPUT_FORMAT        Output format for Claude (default: text)
    CLAUDE_ALLOWED_TOOLS        Tools allowed for Claude
    CLAUDE_BINARY               Path to Claude binary
    CLAUDE_EXTRA_ARGS           Additional arguments for Claude

EXAMPLES:
    $SCRIPT_NAME                           # Standard review
    $SCRIPT_NAME --debug                   # Debug mode
    $SCRIPT_NAME --dry-run                 # Show command without executing
    $SCRIPT_NAME --prompt-path ./my-prompt # Use custom prompt

For more information, visit: https://github.com/anthropics/claude-code
EOF
}

# Show version information
show_version() {
    echo "$SCRIPT_NAME version $SCRIPT_VERSION"
}

# Validate prerequisites
validate_environment() {
    local errors=0

    # Check if we're in a git repository
    if ! git rev-parse --git-dir >/dev/null 2>&1; then
        print_error "Not in a git repository"
        ((errors++))
    fi

    # Check if Claude binary exists
    if ! command -v "$CLAUDE_BINARY" >/dev/null 2>&1; then
        print_error "Claude binary not found: $CLAUDE_BINARY"
        print_info "Install Claude or set CLAUDE_BINARY environment variable"
        ((errors++))
    fi

    # Check if prompt file exists (only if external prompt specified)
    if [[ -n "$CLAUDE_REVIEW_PROMPT_PATH" && ! -f "$CLAUDE_REVIEW_PROMPT_PATH" ]]; then
        print_error "External prompt file not found: $CLAUDE_REVIEW_PROMPT_PATH"
        print_info "File does not exist, will use embedded prompt instead"
        CLAUDE_REVIEW_PROMPT_PATH=""  # Fall back to embedded
    fi

    # Check if there are staged changes
    if ! git diff --cached --quiet; then
        print_info "Found staged changes to review"
    else
        print_warn "No staged changes found. Use 'git add' to stage files for review."
    fi

    return $errors
}

# =============================================================================
# MAIN FUNCTIONALITY
# =============================================================================

# Execute the Claude review
execute_review() {
    local debug_mode="$1"
    local quiet_mode="$2"
    local dry_run="$3"

    # Determine prompt source
    local prompt_source
    if [[ -n "$CLAUDE_REVIEW_PROMPT_PATH" ]]; then
        prompt_source="cat \"$CLAUDE_REVIEW_PROMPT_PATH\""
    else
        prompt_source="get_review_prompt"
    fi

    # Build the command
    local cmd=(
        "$prompt_source"
        "|"
        "$CLAUDE_BINARY"
        --input-format "$CLAUDE_INPUT_FORMAT"
        --output-format "$CLAUDE_OUTPUT_FORMAT"
        --allowedTools "'"$CLAUDE_ALLOWED_TOOLS"'"
        --print
        --verbose
    )

    # Add extra arguments if specified
    if [[ -n "$CLAUDE_EXTRA_ARGS" ]]; then
        cmd+=($CLAUDE_EXTRA_ARGS)
    fi

    # Join command for display/execution
    local full_command="${cmd[*]}"

    if [[ "$debug_mode" == "true" ]]; then
        print_info "Executing command: $full_command"
        if [[ -n "$CLAUDE_REVIEW_PROMPT_PATH" ]]; then
            print_info "Using external prompt: $CLAUDE_REVIEW_PROMPT_PATH"
        else
            print_info "Using embedded prompt"
        fi
        print_info "Claude binary: $CLAUDE_BINARY"
    fi

    if [[ "$dry_run" == "true" ]]; then
        echo "Would execute:"
        echo "$full_command"
        return 0
    fi

    if [[ "$quiet_mode" == "false" ]]; then
        if [[ -n "$CLAUDE_REVIEW_PROMPT_PATH" ]]; then
            print_info "Analyzing staged changes with Claude (external prompt)..."
        else
            print_info "Analyzing staged changes with Claude (embedded prompt)..."
        fi
    fi

    # Execute the command
    eval "$full_command"
    local exit_code=$?

    if [[ $exit_code -eq 0 ]]; then
        if [[ "$quiet_mode" == "false" ]]; then
            print_success "Review completed successfully"
        fi
    else
        print_error "Claude execution failed with exit code $exit_code"
        return $exit_code
    fi
}

# =============================================================================
# ARGUMENT PARSING
# =============================================================================

main() {
    local debug_mode="false"
    local quiet_mode="false"
    local dry_run="false"

    # Parse command line arguments
    while [[ $# -gt 0 ]]; do
        case $1 in
            -h|--help)
                show_usage
                exit 0
                ;;
            -v|--version)
                show_version
                exit 0
                ;;
            -d|--debug)
                debug_mode="true"
                shift
                ;;
            -q|--quiet)
                quiet_mode="true"
                shift
                ;;
            --dry-run)
                dry_run="true"
                shift
                ;;
            --prompt-path)
                CLAUDE_REVIEW_PROMPT_PATH="$2"
                shift 2
                ;;
            --claude-binary)
                CLAUDE_BINARY="$2"
                shift 2
                ;;
            -*)
                print_error "Unknown option: $1"
                show_usage
                exit 1
                ;;
            *)
                print_error "Unexpected argument: $1"
                show_usage
                exit 1
                ;;
        esac
    done

    # Validate environment
    if ! validate_environment; then
        exit 1
    fi

    # Execute the review
    execute_review "$debug_mode" "$quiet_mode" "$dry_run"
}

# =============================================================================
# SCRIPT EXECUTION
# =============================================================================

# Only run main if script is executed directly (not sourced)
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi
